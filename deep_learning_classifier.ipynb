{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Classifier (Melinda Xiao-Devins)\n",
    "\n",
    "Implement deep learning modle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda/envs/em_hack_mac/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/em_hack_mac/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: No GPU found. Please use a GPU to train your neural network.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.layers.core import Dense\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.1'), 'Please use TensorFlow version 1.1 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    " warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    " print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 376516\n",
      "Toatl numver of features: 38\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "#df = pd.read_csv('./data/ny_hmda_2015_normalize.csv', low_memory=False, header=0, delimiter=\",\")\n",
    "df = pd.read_csv('./data/ny_hmda_2015_minmax.csv', low_memory=False, header=0, delimiter=\",\")\n",
    "\n",
    "#print(dataframe.loc[:,:])\n",
    "num_rows = df.shape[0]\n",
    "num_col = df.shape[1]\n",
    "print (\"Total number of records: {}\".format(num_rows))\n",
    "print (\"Toatl numver of features: {}\".format(num_col))\n",
    "\n",
    "dataset = df.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,1:num_col]\n",
    "Y = dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split into train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create model\n",
    "\n",
    "#create a sequencial model and add layers one at a time\n",
    "model = Sequential()\n",
    "\n",
    "# Create a fully connected network with 3 layers\n",
    "#input layer, it has 12 neurons, it must have right number of inputs, which is the number of features\n",
    "model.add(Dense(64, input_dim = num_col-1, activation = 'relu'))\n",
    "\n",
    "# hideen layer has 8 neurons\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "# output layer has 1 neuron to predict\n",
    "# Use sigmoid for output layer activation function to ensure network output is bw. 0 and 1\n",
    "model.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile model\n",
    "\n",
    "# loss function: logarithmic loss, which is binary_crossentropy for binary classification\n",
    "# use 'adam' optimizer for gradient descent algorithm \n",
    "# collect accuracy during training\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "301212/301212 [==============================] - 2s 5us/step - loss: 0.3690 - acc: 0.8086\n",
      "Epoch 2/5\n",
      "301212/301212 [==============================] - 1s 4us/step - loss: 0.3330 - acc: 0.8313\n",
      "Epoch 3/5\n",
      "301212/301212 [==============================] - 1s 4us/step - loss: 0.3301 - acc: 0.8327\n",
      "Epoch 4/5\n",
      "301212/301212 [==============================] - 1s 3us/step - loss: 0.3280 - acc: 0.8343\n",
      "Epoch 5/5\n",
      "301212/301212 [==============================] - 1s 3us/step - loss: 0.3275 - acc: 0.8344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ac0cef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# epochs: a fixed number of iterations through the dataset\n",
    "# batch size: the number of instances that are evaluated before a weight update in the network is performed \n",
    "model.fit(X_train, Y_train, epochs = 5, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75304/75304 [==============================] - 1s 15us/step\n",
      "\n",
      "acc: 83.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction bw. 0 and 1\n",
      "[[ 0.6116094]\n",
      " [ 1.       ]\n",
      " [ 0.6312809]\n",
      " ..., \n",
      " [ 1.       ]\n",
      " [ 1.       ]\n",
      " [ 1.       ]]\n",
      "the rounded prediction\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "print(\"the prediction bw. 0 and 1\")\n",
    "print(predictions)\n",
    "\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(\"the rounded prediction\")\n",
    "print(rounded[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use scikit-learn to evaluate the model using stratified k-fold cross validation. This is a resampling technique that will provide an estimate of the performance of the model. It does this by splitting the data into k-parts, training the model on all parts except one which is held out as a test set to evaluate the performance of the model. This process is repeated k-times and the average score across all constructed models is used as a robust estimate of performance. It is stratified, meaning that it will look at the output values and attempt to balance the number of instances that belong to each class in the k-splits of the data.\n",
    "\n",
    "To use Keras models with scikit-learn, we must use the KerasClassifier wrapper. This class takes a function that creates and returns our neural network model. It also takes arguments that it will pass along to the call to fit() such as the number of epochs and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 48s 142us/step - loss: 0.3324 - acc: 0.8337\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 49s 146us/step - loss: 0.3216 - acc: 0.8398\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 49s 146us/step - loss: 0.3196 - acc: 0.8412\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 49s 146us/step - loss: 0.3179 - acc: 0.8421\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 49s 144us/step - loss: 0.3166 - acc: 0.8431\n",
      "37652/37652 [==============================] - 3s 70us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 50s 146us/step - loss: 0.3322 - acc: 0.8335\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 48s 142us/step - loss: 0.3215 - acc: 0.8403\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 169s 499us/step - loss: 0.3190 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 461s 1ms/step - loss: 0.3179 - acc: 0.8425\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 64s 188us/step - loss: 0.3167 - acc: 0.8428\n",
      "37652/37652 [==============================] - 3s 84us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 62s 184us/step - loss: 0.3323 - acc: 0.8333\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 61s 181us/step - loss: 0.3219 - acc: 0.8397\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 66s 194us/step - loss: 0.3204 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 65s 193us/step - loss: 0.3174 - acc: 0.8422\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 57s 167us/step - loss: 0.3162 - acc: 0.8431\n",
      "37652/37652 [==============================] - 3s 77us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 56s 165us/step - loss: 0.3330 - acc: 0.8339\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 55s 163us/step - loss: 0.3228 - acc: 0.8397\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 51s 152us/step - loss: 0.3195 - acc: 0.8413\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 83s 244us/step - loss: 0.3182 - acc: 0.8425\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 60s 176us/step - loss: 0.3167 - acc: 0.8434\n",
      "37652/37652 [==============================] - 3s 85us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 60s 176us/step - loss: 0.3321 - acc: 0.8333\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 59s 173us/step - loss: 0.3221 - acc: 0.8394\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 56s 167us/step - loss: 0.3196 - acc: 0.8413\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 52s 154us/step - loss: 0.3182 - acc: 0.8424\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 167s 494us/step - loss: 0.3170 - acc: 0.8424\n",
      "37652/37652 [==============================] - 4s 97us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 74s 218us/step - loss: 0.3327 - acc: 0.8328\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 65s 192us/step - loss: 0.3223 - acc: 0.8397\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 354s 1ms/step - loss: 0.3196 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 45s 134us/step - loss: 0.3190 - acc: 0.8425\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 172s 507us/step - loss: 0.3172 - acc: 0.8429\n",
      "37652/37652 [==============================] - 4s 99us/step\n",
      "Epoch 1/5\n",
      "338864/338864 [==============================] - 65s 192us/step - loss: 0.3323 - acc: 0.8337\n",
      "Epoch 2/5\n",
      "338864/338864 [==============================] - 64s 188us/step - loss: 0.3218 - acc: 0.8398\n",
      "Epoch 3/5\n",
      "338864/338864 [==============================] - 47s 138us/step - loss: 0.3188 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338864/338864 [==============================] - 54s 160us/step - loss: 0.3174 - acc: 0.8427\n",
      "Epoch 5/5\n",
      "338864/338864 [==============================] - 45s 133us/step - loss: 0.3160 - acc: 0.8434\n",
      "37652/37652 [==============================] - 3s 77us/step\n",
      "Epoch 1/5\n",
      "338865/338865 [==============================] - 278s 821us/step - loss: 0.3333 - acc: 0.8332\n",
      "Epoch 2/5\n",
      "338865/338865 [==============================] - 49s 144us/step - loss: 0.3223 - acc: 0.8397\n",
      "Epoch 3/5\n",
      "338865/338865 [==============================] - 54s 161us/step - loss: 0.3197 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338865/338865 [==============================] - 54s 161us/step - loss: 0.3179 - acc: 0.8427\n",
      "Epoch 5/5\n",
      "338865/338865 [==============================] - 56s 166us/step - loss: 0.3168 - acc: 0.8437\n",
      "37651/37651 [==============================] - 3s 74us/step\n",
      "Epoch 1/5\n",
      "338865/338865 [==============================] - 57s 168us/step - loss: 0.3319 - acc: 0.8334\n",
      "Epoch 2/5\n",
      "338865/338865 [==============================] - 60s 178us/step - loss: 0.3221 - acc: 0.8394\n",
      "Epoch 3/5\n",
      "338865/338865 [==============================] - 55s 163us/step - loss: 0.3195 - acc: 0.8415\n",
      "Epoch 4/5\n",
      "338865/338865 [==============================] - 55s 161us/step - loss: 0.3183 - acc: 0.8423\n",
      "Epoch 5/5\n",
      "338865/338865 [==============================] - 49s 145us/step - loss: 0.3176 - acc: 0.8429\n",
      "37651/37651 [==============================] - 3s 82us/step\n",
      "Epoch 1/5\n",
      "338866/338866 [==============================] - 50s 148us/step - loss: 0.3322 - acc: 0.8339\n",
      "Epoch 2/5\n",
      "338866/338866 [==============================] - 46s 136us/step - loss: 0.3221 - acc: 0.8395\n",
      "Epoch 3/5\n",
      "338866/338866 [==============================] - 49s 144us/step - loss: 0.3190 - acc: 0.8408\n",
      "Epoch 4/5\n",
      "338866/338866 [==============================] - 52s 153us/step - loss: 0.3172 - acc: 0.8424\n",
      "Epoch 5/5\n",
      "338866/338866 [==============================] - 49s 144us/step - loss: 0.3165 - acc: 0.8424\n",
      "37650/37650 [==============================] - 3s 77us/step\n",
      "Larger: 84.25% (0.17%)\n"
     ]
    }
   ],
   "source": [
    "# larger model\n",
    "def create_large_model():\n",
    "    # Create a fully connected network with 5 layers\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer, it has 256 neurons, it must have right number of inputs, which is the number of features\n",
    "    model.add(Dense(256, input_dim=num_col-1, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    # hideen layer has 128 neurons\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "        \n",
    "    # hideen layer has 64 neurons\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "        \n",
    "     # hideen layer has 32 neurons\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "  \n",
    "    # output layer has 1 neuron to predict\n",
    "    # Use sigmoid for output layer activation function to ensure network output is bw. 0 and 1\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# TODO: epochs = 150\n",
    "large_model = KerasClassifier(build_fn=create_large_model, epochs=5, batch_size=10, verbose=1)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "\n",
    "estimators.append(('mlp', large_model))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a792b0612548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the prediction bw. 0 and 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "\n",
    "predictions = large_model.predict(X)\n",
    "print(\"the prediction bw. 0 and 1\")\n",
    "print(predictions)\n",
    "\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(\"the rounded prediction\")\n",
    "print(rounded[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(y_test, large_model.predict(x_test),average=\"macro\")\n",
    "print(\"precision={}, recall={}, fscore={}, support={}\".format(precision, recall, fscore, support))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
