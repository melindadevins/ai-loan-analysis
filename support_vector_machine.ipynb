{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Support_Vector_Machine  (Vincent and Tian)\n",
    "\n",
    "Support vector machines (SVM) use a mechanism called kernels, which essentially calculate distance between two observations. The SVM algorithm then finds a decision boundary that maximizes the distance between the closest members of separate classes.\n",
    "\n",
    "For example, an SVM with a linear kernel is similar to logistic regression. Therefore, in practice, the benefit of SVM's typically comes from using non-linear kernels to model non-linear decision boundaries.\n",
    "\n",
    "Strengths: SVM's can model non-linear decision boundaries, and there are many kernels to choose from. They are also fairly robust against overfitting, especially in high-dimensional space.\n",
    "\n",
    "Weaknesses: However, SVM's are memory intensive, trickier to tune due to the importance of picking the right kernel, and don't scale well to larger datasets. Currently in the industry, random forests are usually preferred over SVM's.\n",
    "\n",
    "Reference: http://scikit-learn.org/stable/modules/svm.html#classification\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/em_hack_mac/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import svm\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.47072697787\n"
     ]
    }
   ],
   "source": [
    "#LinearSVR Minmax \n",
    "df_minimax = pd.read_csv('./data/ny_hmda_2015_minmax.csv')\n",
    "\n",
    "x_minimax = np.array(df_minimax.drop(['action_taken'],1)) \n",
    "y_minimax = np.array(df_minimax['action_taken'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_minimax,y_minimax,test_size = 0.2)\n",
    "print(LinearSVR().fit(x_train, y_train).score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823913736322\n"
     ]
    }
   ],
   "source": [
    "#LinearSVR Minmax\n",
    "linSVC = LinearSVC()\n",
    "linSVC.fit(x_train, y_train)\n",
    "print(linSVC.score(x_test,y_test))\n",
    "cPickle.dump(linSVC,open('models/linear_svc_model.p','wb'))\n",
    "\n",
    "# print(LinearSVC().fit(x_train, y_train).score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_robust = pd.read_csv('./data/ny_hmda_2015_robust.csv')\n",
    "\n",
    "x_robust = np.array(df_robust.drop(['action_taken'],1)) \n",
    "y_robust = np.array(df_robust['action_taken'])\n",
    "scores_robust = cross_val_score(SVC(), x_robust, y_robust, scoring='accuracy', cv=10)\n",
    "print(scores_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_minimax = pd.read_csv('./data/ny_hmda_2015_minimax.csv')\n",
    "\n",
    "x_minimax = np.array(df_minimax.drop(['action_taken'],1)) \n",
    "y_minimax = np.array(df_minimax['action_taken'])\n",
    "scores_minimax = cross_val_score(SVC(), x_minimax, y_minimax, scoring='accuracy', cv=10)\n",
    "print(scores_minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normalize = pd.read_csv('./data/ny_hmda_2015_normalize.csv')\n",
    "\n",
    "x_normalize = np.array(df_normalize.drop(['action_taken'],1)) \n",
    "y_normalize = np.array(df_normalize['action_taken'])\n",
    "scores_normalize = cross_val_score(SVC(), x_normalize, y_normalize, scoring='accuracy', cv=10)\n",
    "print(scores_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC\n",
    "df = pd.read_csv('./data/ny_hmda_2015_minmax.csv')\n",
    "x = np.array(df.drop(['action_taken'],1)) \n",
    "y = np.array(df['action_taken'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "cPickle.dump(clf,open('models/svc_model.p','wb'))\n",
    "accuracy = clf.score(x_test,y_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
