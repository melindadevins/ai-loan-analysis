{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression  (Vicent Liu)\n",
    "\n",
    "Logistic regression is the classification counterpart to linear regression. Predictions are mapped to be between 0 and 1 through the logistic function, which means that predictions can be interpreted as class probabilities.\n",
    "The models themselves are still \"linear,\" so they work well when your classes are linearly separable (i.e. they can be separated by a single decision surface). Logistic regression can also be regularized by penalizing coefficients with a tunable penalty strength.\n",
    "\n",
    "Strengths: Outputs have a nice probabilistic interpretation, and the algorithm can be regularized to avoid overfitting. \n",
    "    Logistic models can be updated easily with new data using stochastic gradient descent. \n",
    "    \n",
    "Weaknesses: Logistic regression tends to underperform when there are multiple or non-linear decision boundaries. They are not flexible enough to naturally capture more complex relationships.\n",
    "\n",
    "Reference: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/em_hack_mac/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/ny_hmda_2015_minmax.csv')\n",
    "\n",
    "x = np.array(df.drop(['action_taken'],1)) \n",
    "y = np.array(df['action_taken'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e4)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82411292892807819"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Z = logreg.predict(X)\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824019972379\n",
      "0.82419260597\n",
      "0.824112928928\n",
      "0.824112928928\n",
      "0.824112928928\n",
      "0.824099649421\n",
      "0.824126208435\n",
      "0.824099649421\n",
      "0.824112928928\n",
      "0.824112928928\n"
     ]
    }
   ],
   "source": [
    "#test different C\n",
    "for i in range(10):\n",
    "    logreg = linear_model.LogisticRegression(C=10**i)\n",
    "    print(logreg.fit(x_train, y_train).score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824046531393\n",
      "0.824152767449\n",
      "0.824152767449\n",
      "0.824139487942\n",
      "0.824152767449\n",
      "0.82419260597\n",
      "0.824152767449\n",
      "0.824166046956\n",
      "0.824166046956\n",
      "0.824166046956\n"
     ]
    }
   ],
   "source": [
    "#test penalty = l1\n",
    "for i in range(10):\n",
    "    logreg = linear_model.LogisticRegression(C=10**i, penalty='l1')\n",
    "    print(logreg.fit(x_train, y_train).score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825520556677\n"
     ]
    }
   ],
   "source": [
    "#TEST NORM DATASET\n",
    "df_norm = pd.read_csv('./data/ny_hmda_2015_normalize.csv')\n",
    "\n",
    "x_norm = np.array(df.drop(['action_taken'],1)) \n",
    "y_norm = np.array(df['action_taken'])\n",
    "x_train_norm, x_test_norm, y_train_norm, y_test_norm = train_test_split(x_norm,y_norm,test_size = 0.2)\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "print(logreg.fit(x_train_norm, y_train_norm).score(x_test_norm, y_test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825719749283\n"
     ]
    }
   ],
   "source": [
    "#TEST ROBUST DATASET\n",
    "df_robust = pd.read_csv('./data/ny_hmda_2015_robust.csv')\n",
    "\n",
    "x_robust = np.array(df.drop(['action_taken'],1)) \n",
    "y_robust = np.array(df['action_taken'])\n",
    "x_train_robust, x_test_robust, y_train_robust, y_test_robust = train_test_split(x_robust,y_robust,test_size = 0.2)\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "print(logreg.fit(x_train_robust, y_train_robust).score(x_test_robust, y_test_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81310422  0.83084564  0.85190694  0.8464889   0.81897376  0.81530862\n",
      "  0.82980984  0.80887626  0.68813577  0.8890571 ]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "scores = cross_val_score(linear_model.LogisticRegression(), x_robust, y_robust, scoring='accuracy', cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
